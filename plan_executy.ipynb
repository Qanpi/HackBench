{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ddfc055",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "059d0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \"langchain-google-genai\" langchain-google-vertexai \"openai\" \"langchainhub\" \"pandas\" \"tqdm\" \"pydantic\" \"python-dotenv\" langgraph langchain langgraph-supervisor \n",
    "!pip install -qU \"langchain-unstructured[local]\" langchain-community langchain-opentutorial\n",
    "!pip install -qU langsmith openevals openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f773428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f573c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "MODEL_NAME = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8425f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_opentutorial.graphs import visualize_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e233299",
   "metadata": {},
   "source": [
    "### Challenge info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00241657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('02', 'http://localhost:3000')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHALLENGE_ID = \"02\"\n",
    "URL = None\n",
    "\n",
    "root_dir = 'noitatiolpxe_bew'\n",
    "ev_path = root_dir[::-1] + f'/EV-{CHALLENGE_ID}'\n",
    "\n",
    "import json\n",
    "\n",
    "with open(os.path.join(ev_path, 'challenge.json'), 'r') as f:\n",
    "    challenge = json.load(f)\n",
    "    URL = challenge['url']\n",
    "\n",
    "URL = URL.replace('host.docker.internal', 'localhost') #FIXME: TEMP!\n",
    "CHALLENGE_ID, URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "483cb941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    ev_path + '/application',\n",
    "    exclude=['Dockerfile', 'docker-entrypoint.sh'],\n",
    "    loader_cls=TextLoader\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45089c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Define the prompt\n",
    "executor_system_prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "\"\"\"\n",
    "\n",
    "# Define the LLM\n",
    "llm = init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0 #is this the correct syntax? \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "254bb2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "test = python_repl.run(f'''\n",
    "import requests\n",
    "\n",
    "test = requests.get('{URL}')                \n",
    "print(test.status_code)\n",
    "\n",
    "''')\n",
    "print(test)\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    func=python_repl.run,\n",
    "    description=\"A Python code REPL. Use this to automate tasks that require many repetitions. Input should be a valid python program. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    return_direct=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64fd2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ReAct agent\n",
    "agent_executor = create_react_agent(model=llm, tools=[repl_tool], prompt=executor_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7b4ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# State definition\n",
    "class PlanExecute(TypedDict):\n",
    "    input: Annotated[str, \"User's input\"]\n",
    "    plan: Annotated[List[str], \"Current plan\"]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: Annotated[str, \"Final response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c59fcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Define Plan model\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Sorted steps to execute the plan\"\"\"\n",
    "\n",
    "    steps: Annotated[List[str], \"Different steps to follow, should be in sorted order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed15c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_system_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "For the given objective, come up with a simple step by step plan.\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps.\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\"\"\")\n",
    "\n",
    "planner_agent = planner_system_prompt | init_chat_model(\n",
    "    model=MODEL_NAME,\n",
    ").with_structured_output(Plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82d4e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "# Define the prompt for re-planning\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the following steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed return AN EMPTY PLAN. You do not need to include past steps in the plan.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the replanner\n",
    "replanner = replanner_prompt | init_chat_model(\n",
    "    model=MODEL_NAME\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b7db1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps=[])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt = \"\"\"\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the following steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\n",
    "\"\"\"\n",
    "\n",
    "test_input = replanner.invoke({\n",
    "    'input': \"Get the status code of the page\",\n",
    "    'plan': [\"Get the status code of the page\"],\n",
    "    'past_steps': [(\"Get the status code of the page\", 200)]\n",
    "})\n",
    "\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05665750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# Generate and return a plan based on user input\n",
    "def plan_step(state: PlanExecute):\n",
    "    plan = planner_agent.invoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    # Return the list of steps from the generated plan\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "# Use the agent executor to perform the specified task and return the result\n",
    "def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    # Convert the plan to a string, enumerating each step\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    # Format the current task for the agent\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing [step 1. {task}].\"\"\"\n",
    "    # Use the agent executor to perform the task and get the result\n",
    "    agent_response = agent_executor.invoke({\"messages\": [(\"user\", task_formatted)]})\n",
    "    # Return a dictionary containing the previous step and its result\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
    "    }\n",
    "\n",
    "\n",
    "# Update the plan or return the final response based on the results of the previous step\n",
    "def replan_step(state: PlanExecute):\n",
    "    output = replanner.invoke(state)\n",
    "\n",
    "    # If more steps are needed\n",
    "    next_plan = output.steps\n",
    "    if len(next_plan) == 0:\n",
    "        return {\"response\": \"No more steps needed.\"}\n",
    "    else:\n",
    "        return {\"plan\": next_plan}\n",
    "\n",
    "\n",
    "# A function that decides whether to end the agent's execution\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"final_report\"\n",
    "    else:\n",
    "        return \"execute\"\n",
    "\n",
    "\n",
    "final_report_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are given the objective and the previously done steps. Your task is to generate a final report in markdown format.\n",
    "Final report should be written in professional tone.\n",
    "\n",
    "Your objective was this:\n",
    "\n",
    "{input}\n",
    "\n",
    "Your previously done steps(question and answer pairs):\n",
    "\n",
    "{past_steps}\n",
    "\n",
    "Generate a final report in markdown format.\"\"\"\n",
    ")\n",
    "\n",
    "final_report = (\n",
    "    final_report_prompt\n",
    "    | init_chat_model(model=MODEL_NAME, temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "def generate_final_report(state: PlanExecute):\n",
    "    past_steps = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"Question: {past_step[0]}\\n\\nAnswer: {past_step[1]}\\n\\n####\"\n",
    "            for past_step in state[\"past_steps\"]\n",
    "        ]\n",
    "    )\n",
    "    response = final_report.invoke({\"input\": state[\"input\"], \"past_steps\": past_steps})\n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "627075b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# Create the workflow graph\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Define nodes\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "workflow.add_node(\"execute\", execute_step)\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "workflow.add_node(\"final_report\", generate_final_report)\n",
    "\n",
    "# Define edges\n",
    "workflow.add_edge(START, \"planner\")\n",
    "workflow.add_edge(\"planner\", \"execute\")\n",
    "workflow.add_edge(\"execute\", \"replan\")\n",
    "workflow.add_edge(\"final_report\", END)\n",
    "\n",
    "# Conditional edges: use should_end function to decide whether to stop\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    should_end,\n",
    "    {\"execute\": \"execute\", \"final_report\": \"final_report\"},\n",
    ")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb935a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  +-----------+  \\n  | __start__ |  \\n  +-----------+  \\n        *        \\n        *        \\n        *        \\n  +---------+    \\n  | planner |    \\n  +---------+    \\n        *        \\n        *        \\n        *        \\n  +---------+    \\n  | execute |    \\n  +---------+    \\n        *        \\n        *        \\n        *        \\n   +--------+    \\n   | replan |    \\n   +--------+    \\n        .        \\n        .        \\n        .        \\n+--------------+ \\n| final_report | \\n+--------------+ \\n        *        \\n        *        \\n        *        \\n  +---------+    \\n  | __end__ |    \\n  +---------+    '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "app.get_graph().draw_ascii()\n",
    "\n",
    "# Image(app.get_graph(xray=True).draw_mermaid_png(output_file_path=\"05-langgraph-plan-and-execute.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4e94e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': ['List the steps required to fulfill the objective.']}\n",
      "{'past_steps': [('List the steps required to fulfill the objective.', 'Okay, I understand. To list the steps required to fulfill the objective, I need to first understand what the objective is. Please provide the objective. Once I have the objective, I can list the steps required to achieve it.\\n')]}\n",
      "{'plan': ['Define AI Agents.', 'Explain the key components of AI Agents.', 'Describe the different types of AI Agents.', 'Discuss the applications of AI Agents.', 'Summarize the explanation of AI Agents.']}\n",
      "{'past_steps': [('Define AI Agents.', 'AI agents are autonomous entities, either software or hardware-based, that can perceive their environment through sensors, reason about their observations, and act upon that environment to achieve specific goals. They can be designed to be simple or complex, and they often exhibit characteristics such as learning, adaptation, and decision-making.\\n')]}\n",
      "{'plan': ['Explain the key components of AI Agents, such as perception, reasoning, and action.', 'Describe the different types of AI Agents, including simple reflex agents, model-based reflex agents, goal-based agents, and utility-based agents.', 'Discuss the applications of AI Agents in various domains, such as robotics, natural language processing, and computer vision.', 'Summarize the explanation of AI Agents.']}\n",
      "{'past_steps': [('Explain the key components of AI Agents, such as perception, reasoning, and action.', 'Okay, let\\'s break down the key components of AI Agents: perception, reasoning, and action.\\n\\n*   **Perception:** This is how an AI Agent gathers information from its environment. Think of it as the agent\\'s senses. Perception involves:\\n    *   **Sensors:** These could be physical sensors like cameras, microphones, or temperature sensors, or virtual sensors like APIs that provide data.\\n    *   **Data Acquisition:** The agent needs to collect data from these sensors.\\n    *   **Data Preprocessing:** Raw data is often noisy or incomplete. Preprocessing cleans and transforms the data into a usable format. This might involve filtering, noise reduction, or feature extraction.\\n    *   **Environment Understanding:** The agent uses the processed data to build a representation of its environment.\\n\\n*   **Reasoning:** This is the agent\\'s \"thinking\" process. It involves:\\n    *   **Knowledge Representation:** How the agent stores and organizes information about the world. This could be in the form of rules, frames, semantic networks, or probabilistic models.\\n    *   **Inference:** The process of drawing conclusions and making predictions based on the agent\\'s knowledge and perceptions. This might involve logical deduction, probabilistic reasoning, or machine learning.\\n    *   **Decision-Making:** Choosing the best course of action to achieve its goals. This often involves evaluating different options and considering their potential consequences.\\n\\n*   **Action:** This is how the AI Agent interacts with its environment. It involves:\\n    *   **Effectors:** These are the mechanisms the agent uses to perform actions. They could be physical actuators like motors or virtual actuators like commands sent to a software system.\\n    *   **Action Planning:** Determining the sequence of actions needed to achieve a goal.\\n    *   **Execution:** Carrying out the planned actions.\\n    *   **Feedback:** Receiving information about the effects of its actions and using this information to improve its performance. This closes the loop, allowing the agent to learn and adapt.\\n\\nIn essence, an AI agent perceives its environment, reasons about it, and then acts upon it. These three components work together to enable the agent to achieve its goals.\\n')]}\n",
      "{'plan': ['Describe the different types of AI Agents, including simple reflex agents, model-based reflex agents, goal-based agents, and utility-based agents.', 'Discuss the applications of AI Agents in various domains, such as robotics, natural language processing, and computer vision.', 'Summarize the explanation of AI Agents.']}\n",
      "{'past_steps': [('Describe the different types of AI Agents, including simple reflex agents, model-based reflex agents, goal-based agents, and utility-based agents.', 'Okay, let\\'s describe the different types of AI Agents:\\n\\n*   **Simple Reflex Agents:** These are the simplest type of agent. They react directly to the current percept (input) without considering past experiences or future consequences. They have a condition-action rule: \"If condition, then action.\" Their knowledge is limited to what they can perceive at the moment. A thermostat is a good example.\\n\\n*   **Model-Based Reflex Agents:** These agents maintain an internal \"model\" of the world, which represents the agent\\'s understanding of how the world works. This model is updated based on percepts and is used to infer hidden aspects of the current state. They use this model to choose actions, especially when the percept doesn\\'t fully determine the best action.\\n\\n*   **Goal-Based Agents:** These agents have a specific goal or set of goals they are trying to achieve. They use their model of the world to evaluate which actions will lead them closer to their goals. Goal-based agents can handle more complex environments than reflex agents because they consider the future consequences of their actions.\\n\\n*   **Utility-Based Agents:** These agents go beyond simply having goals; they also have a \"utility function\" that assigns a value (utility) to different states. This allows them to make decisions that maximize their overall \"happiness\" or \"well-being.\" Utility-based agents are useful when there are multiple possible goals, some of which are more desirable than others. They can also handle situations where achieving a goal is uncertain.\\n')]}\n",
      "{'plan': ['Discuss the applications of AI Agents in various domains, such as robotics, natural language processing, and computer vision.', 'Summarize the explanation of AI Agents.']}\n",
      "{'past_steps': [('Discuss the applications of AI Agents in various domains, such as robotics, natural language processing, and computer vision.', \"Okay, let's discuss the applications of AI Agents in various domains:\\n\\n*   **Robotics:** AI agents are used to control robots, enabling them to perform tasks autonomously in complex and dynamic environments. For example, in manufacturing, AI-powered robots can assemble products, handle materials, and perform quality control. In exploration, robots equipped with AI can navigate unknown terrains, collect data, and perform scientific experiments.\\n\\n*   **Natural Language Processing (NLP):** AI agents are crucial in NLP for tasks like chatbots, virtual assistants, and language translation. They can understand and respond to human language, providing information, completing tasks, and engaging in conversations. Examples include customer service chatbots, voice assistants like Siri and Alexa, and machine translation tools.\\n\\n*   **Computer Vision:** AI agents are used to analyze and interpret images and videos. They can identify objects, detect anomalies, and track movements. Applications include self-driving cars, medical image analysis, security surveillance, and facial recognition systems. For instance, in self-driving cars, AI agents use computer vision to perceive the environment, detect obstacles, and navigate roads.\\n\")]}\n",
      "{'plan': ['Summarize the explanation of AI Agents.']}\n",
      "{'past_steps': [('Summarize the explanation of AI Agents.', 'Please provide the explanation of AI Agents that I need to summarize. I need the text to be able to complete the task.\\n')]}\n",
      "{'plan': ['Summarize the definition, key components, types, and applications of AI Agents.']}\n",
      "{'past_steps': [('Summarize the definition, key components, types, and applications of AI Agents.', 'Okay, I can summarize the definition, key components, types, and applications of AI Agents. Here\\'s the information:\\n\\n**Definition:**\\n\\nAn AI agent is an autonomous entity that perceives its environment through sensors and acts upon that environment through actuators to achieve a specific goal. It can be a software program, a robot, or any other entity capable of intelligent behavior.\\n\\n**Key Components:**\\n\\n*   **Perception:** The ability to sense and interpret the environment using sensors.\\n*   **Reasoning:** The ability to process information, make decisions, and plan actions.\\n*   **Action:** The ability to execute actions on the environment through actuators.\\n*   **Learning:** The ability to improve performance over time through experience.\\n*   **Autonomy:** The ability to operate independently without constant human intervention.\\n\\n**Types of AI Agents:**\\n\\n*   **Simple Reflex Agents:** These agents react directly to percepts based on pre-defined rules. They have no memory of past states.\\n*   **Model-Based Reflex Agents:** These agents maintain an internal state (a \"model\") of the environment to handle partially observable environments.\\n*   **Goal-Based Agents:** These agents have a goal in mind and try to achieve it by planning and searching for sequences of actions.\\n*   **Utility-Based Agents:** These agents aim to maximize their \"utility\" or happiness, considering multiple factors and trade-offs.\\n*   **Learning Agents:** These agents can learn from experience and adapt their behavior to improve performance.\\n\\n**Applications of AI Agents:**\\n\\n*   **Robotics:** Controlling robots for tasks like manufacturing, exploration, and healthcare.\\n*   **Virtual Assistants:** Providing personalized assistance and information retrieval (e.g., Siri, Alexa).\\n*   **Game Playing:** Creating intelligent game-playing agents (e.g., chess, Go).\\n*   **Recommendation Systems:** Suggesting products, movies, or music based on user preferences.\\n*   **Autonomous Vehicles:** Driving cars and other vehicles without human intervention.\\n*   **Healthcare:** Assisting doctors with diagnosis, treatment planning, and patient monitoring.\\n*   **Finance:** Automating trading, fraud detection, and risk management.\\n')]}\n",
      "{'response': 'No more steps needed.'}\n",
      "{'response': '# AI Agents: An Overview\\n\\nThis report provides an overview of AI agents, covering their definition, key components, types, and applications.\\n\\n## Definition\\n\\nAn AI agent is an autonomous entity, implemented as software or hardware, that perceives its environment through sensors and acts upon that environment through actuators to achieve a specific goal. The agent\\'s intelligence lies in its ability to reason, learn, and adapt to changing conditions.\\n\\n## Key Components\\n\\nAI agents are characterized by the following key components:\\n\\n*   **Perception:** This involves sensing and interpreting the environment. Agents use sensors (physical or virtual) to acquire data, preprocess it to remove noise and extract relevant features, and build a representation of their environment.\\n*   **Reasoning:** This is the agent\\'s \"thinking\" process. It involves knowledge representation (how the agent stores information), inference (drawing conclusions), and decision-making (choosing the best course of action).\\n*   **Action:** This is how the agent interacts with its environment. It involves using effectors (actuators) to perform actions, planning sequences of actions, and executing those actions. Feedback mechanisms allow the agent to learn from the consequences of its actions.\\n*   **Learning:** The ability to improve performance over time through experience.\\n*   **Autonomy:** The ability to operate independently without constant human intervention.\\n\\n## Types of AI Agents\\n\\nDifferent types of AI agents exist, each with varying degrees of complexity and capabilities:\\n\\n*   **Simple Reflex Agents:** These agents react directly to percepts based on pre-defined rules. They have no memory of past states and operate based on a condition-action principle.\\n*   **Model-Based Reflex Agents:** These agents maintain an internal \"model\" of the environment to handle partially observable environments. This model is updated based on percepts and is used to infer hidden aspects of the current state.\\n*   **Goal-Based Agents:** These agents have a specific goal in mind and try to achieve it by planning and searching for sequences of actions. They use their model of the world to evaluate which actions will lead them closer to their goals.\\n*   **Utility-Based Agents:** These agents aim to maximize their \"utility\" or happiness, considering multiple factors and trade-offs. They use a utility function to assign a value to different states, allowing them to make decisions that maximize their overall well-being.\\n\\n## Applications of AI Agents\\n\\nAI agents have a wide range of applications across various domains:\\n\\n*   **Robotics:** Controlling robots for tasks like manufacturing, exploration, and healthcare. AI-powered robots can assemble products, navigate unknown terrains, and assist in surgeries.\\n*   **Natural Language Processing (NLP):** Powering virtual assistants (e.g., Siri, Alexa), chatbots, and machine translation tools. AI agents can understand and respond to human language, providing information and completing tasks.\\n*   **Computer Vision:** Analyzing and interpreting images and videos for applications like self-driving cars, medical image analysis, and security surveillance. AI agents can identify objects, detect anomalies, and track movements.\\n*   **Game Playing:** Creating intelligent game-playing agents (e.g., chess, Go) that can compete with human players.\\n*   **Recommendation Systems:** Suggesting products, movies, or music based on user preferences.\\n*   **Autonomous Vehicles:** Driving cars and other vehicles without human intervention.\\n*   **Healthcare:** Assisting doctors with diagnosis, treatment planning, and patient monitoring.\\n*   **Finance:** Automating trading, fraud detection, and risk management.\\n\\n## Conclusion\\n\\nAI agents are a powerful technology with the potential to transform many aspects of our lives. Their ability to perceive, reason, and act autonomously makes them well-suited for a wide range of applications, from robotics and natural language processing to healthcare and finance. As AI technology continues to advance, we can expect to see even more innovative and impactful applications of AI agents in the future.\\n'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=50, configurable={\"thread_id\": \"1\"})\n",
    "inputs = {\"input\": \"Please explain about AI Agents.\"}\n",
    "\n",
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a97743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AI Agents: An Overview\n",
      "\n",
      "This report provides an overview of AI agents, covering their definition, key components, types, and applications.\n",
      "\n",
      "## Definition\n",
      "\n",
      "An AI agent is an autonomous entity, implemented as software or hardware, that perceives its environment through sensors and acts upon that environment through actuators to achieve a specific goal. The agent's intelligence lies in its ability to reason, learn, and adapt to changing conditions.\n",
      "\n",
      "## Key Components\n",
      "\n",
      "AI agents are characterized by the following key components:\n",
      "\n",
      "*   **Perception:** This involves sensing and interpreting the environment. Agents use sensors (physical or virtual) to acquire data, preprocess it to remove noise and extract relevant features, and build a representation of their environment.\n",
      "*   **Reasoning:** This is the agent's \"thinking\" process. It involves knowledge representation (how the agent stores information), inference (drawing conclusions), and decision-making (choosing the best course of action).\n",
      "*   **Action:** This is how the agent interacts with its environment. It involves using effectors (actuators) to perform actions, planning sequences of actions, and executing those actions. Feedback mechanisms allow the agent to learn from the consequences of its actions.\n",
      "*   **Learning:** The ability to improve performance over time through experience.\n",
      "*   **Autonomy:** The ability to operate independently without constant human intervention.\n",
      "\n",
      "## Types of AI Agents\n",
      "\n",
      "Different types of AI agents exist, each with varying degrees of complexity and capabilities:\n",
      "\n",
      "*   **Simple Reflex Agents:** These agents react directly to percepts based on pre-defined rules. They have no memory of past states and operate based on a condition-action principle.\n",
      "*   **Model-Based Reflex Agents:** These agents maintain an internal \"model\" of the environment to handle partially observable environments. This model is updated based on percepts and is used to infer hidden aspects of the current state.\n",
      "*   **Goal-Based Agents:** These agents have a specific goal in mind and try to achieve it by planning and searching for sequences of actions. They use their model of the world to evaluate which actions will lead them closer to their goals.\n",
      "*   **Utility-Based Agents:** These agents aim to maximize their \"utility\" or happiness, considering multiple factors and trade-offs. They use a utility function to assign a value to different states, allowing them to make decisions that maximize their overall well-being.\n",
      "\n",
      "## Applications of AI Agents\n",
      "\n",
      "AI agents have a wide range of applications across various domains:\n",
      "\n",
      "*   **Robotics:** Controlling robots for tasks like manufacturing, exploration, and healthcare. AI-powered robots can assemble products, navigate unknown terrains, and assist in surgeries.\n",
      "*   **Natural Language Processing (NLP):** Powering virtual assistants (e.g., Siri, Alexa), chatbots, and machine translation tools. AI agents can understand and respond to human language, providing information and completing tasks.\n",
      "*   **Computer Vision:** Analyzing and interpreting images and videos for applications like self-driving cars, medical image analysis, and security surveillance. AI agents can identify objects, detect anomalies, and track movements.\n",
      "*   **Game Playing:** Creating intelligent game-playing agents (e.g., chess, Go) that can compete with human players.\n",
      "*   **Recommendation Systems:** Suggesting products, movies, or music based on user preferences.\n",
      "*   **Autonomous Vehicles:** Driving cars and other vehicles without human intervention.\n",
      "*   **Healthcare:** Assisting doctors with diagnosis, treatment planning, and patient monitoring.\n",
      "*   **Finance:** Automating trading, fraud detection, and risk management.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "AI agents are a powerful technology with the potential to transform many aspects of our lives. Their ability to perceive, reason, and act autonomously makes them well-suited for a wide range of applications, from robotics and natural language processing to healthcare and finance. As AI technology continues to advance, we can expect to see even more innovative and impactful applications of AI agents in the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snapshot = app.get_state(config).values\n",
    "print(snapshot[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3f820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI Agents: An Overview\n",
       "\n",
       "This report provides an overview of AI agents, covering their definition, key components, types, and applications.\n",
       "\n",
       "## Definition\n",
       "\n",
       "An AI agent is an autonomous entity, implemented as software or hardware, that perceives its environment through sensors and acts upon that environment through actuators to achieve a specific goal. The agent's intelligence lies in its ability to reason, learn, and adapt to changing conditions.\n",
       "\n",
       "## Key Components\n",
       "\n",
       "AI agents are characterized by the following key components:\n",
       "\n",
       "*   **Perception:** This involves sensing and interpreting the environment. Agents use sensors (physical or virtual) to acquire data, preprocess it to remove noise and extract relevant features, and build a representation of their environment.\n",
       "*   **Reasoning:** This is the agent's \"thinking\" process. It involves knowledge representation (how the agent stores information), inference (drawing conclusions), and decision-making (choosing the best course of action).\n",
       "*   **Action:** This is how the agent interacts with its environment. It involves using effectors (actuators) to perform actions, planning sequences of actions, and executing those actions. Feedback mechanisms allow the agent to learn from the consequences of its actions.\n",
       "*   **Learning:** The ability to improve performance over time through experience.\n",
       "*   **Autonomy:** The ability to operate independently without constant human intervention.\n",
       "\n",
       "## Types of AI Agents\n",
       "\n",
       "Different types of AI agents exist, each with varying degrees of complexity and capabilities:\n",
       "\n",
       "*   **Simple Reflex Agents:** These agents react directly to percepts based on pre-defined rules. They have no memory of past states and operate based on a condition-action principle.\n",
       "*   **Model-Based Reflex Agents:** These agents maintain an internal \"model\" of the environment to handle partially observable environments. This model is updated based on percepts and is used to infer hidden aspects of the current state.\n",
       "*   **Goal-Based Agents:** These agents have a specific goal in mind and try to achieve it by planning and searching for sequences of actions. They use their model of the world to evaluate which actions will lead them closer to their goals.\n",
       "*   **Utility-Based Agents:** These agents aim to maximize their \"utility\" or happiness, considering multiple factors and trade-offs. They use a utility function to assign a value to different states, allowing them to make decisions that maximize their overall well-being.\n",
       "\n",
       "## Applications of AI Agents\n",
       "\n",
       "AI agents have a wide range of applications across various domains:\n",
       "\n",
       "*   **Robotics:** Controlling robots for tasks like manufacturing, exploration, and healthcare. AI-powered robots can assemble products, navigate unknown terrains, and assist in surgeries.\n",
       "*   **Natural Language Processing (NLP):** Powering virtual assistants (e.g., Siri, Alexa), chatbots, and machine translation tools. AI agents can understand and respond to human language, providing information and completing tasks.\n",
       "*   **Computer Vision:** Analyzing and interpreting images and videos for applications like self-driving cars, medical image analysis, and security surveillance. AI agents can identify objects, detect anomalies, and track movements.\n",
       "*   **Game Playing:** Creating intelligent game-playing agents (e.g., chess, Go) that can compete with human players.\n",
       "*   **Recommendation Systems:** Suggesting products, movies, or music based on user preferences.\n",
       "*   **Autonomous Vehicles:** Driving cars and other vehicles without human intervention.\n",
       "*   **Healthcare:** Assisting doctors with diagnosis, treatment planning, and patient monitoring.\n",
       "*   **Finance:** Automating trading, fraud detection, and risk management.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "AI agents are a powerful technology with the potential to transform many aspects of our lives. Their ability to perceive, reason, and act autonomously makes them well-suited for a wide range of applications, from robotics and natural language processing to healthcare and finance. As AI technology continues to advance, we can expect to see even more innovative and impactful applications of AI agents in the future.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(snapshot[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fab08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
